apiVersion: "serving.kserve.io/v1beta1"
kind: "InferenceService"
metadata:
  name: "xgboost-load-predictor"
  namespace: "ml-scheduler"
  labels:
    app: "xgboost-predictor"
    model-type: "load-prediction"
    version: "v1.0.0"
  annotations:
    serving.kserve.io/deploymentMode: "Serverless"
    autoscaling.knative.dev/metric: "concurrency"
    autoscaling.knative.dev/target: "10"
    autoscaling.knative.dev/targetUtilizationPercentage: "70"
spec:
  predictor:
    serviceAccountName: kserve-service-account
    minReplicas: 2
    maxReplicas: 10
    scaleTarget: 10
    scaleMetric: concurrency
    containerConcurrency: 10
    timeout: 60
    canaryTrafficPercent: 10
    containers:
    - name: kserve-container
      image: xgboost-predictor:latest
      ports:
      - containerPort: 8080
        protocol: TCP
      env:
      - name: STORAGE_URI
        value: "s3://ml-models/xgboost/load-predictor/"
      - name: MODEL_NAME
        value: "xgboost-load-predictor"
      - name: SERVICE_TYPE
        value: "predictor"
      - name: REDIS_HOST
        value: "redis-cache-service"
      - name: REDIS_PORT
        value: "6379"
      - name: MLFLOW_TRACKING_URI
        value: "http://mlflow-server:5000"
      - name: PROMETHEUS_MULTIPROC_DIR
        value: "/tmp/prometheus_metrics"
      - name: LOG_LEVEL
        value: "INFO"
      resources:
        requests:
          cpu: 100m
          memory: 256Mi
        limits:
          cpu: 1000m
          memory: 2Gi
      livenessProbe:
        httpGet:
          path: /v1/models/xgboost-load-predictor/health
          port: 8080
        initialDelaySeconds: 30
        periodSeconds: 30
        timeoutSeconds: 10
        failureThreshold: 3
      readinessProbe:
        httpGet:
          path: /v1/models/xgboost-load-predictor/ready
          port: 8080
        initialDelaySeconds: 10
        periodSeconds: 10
        timeoutSeconds: 5
        failureThreshold: 3
      volumeMounts:
      - name: prometheus-metrics
        mountPath: /tmp/prometheus_metrics
      - name: model-cache
        mountPath: /tmp/model_cache
    volumes:
    - name: prometheus-metrics
      emptyDir: {}
    - name: model-cache
      emptyDir:
        sizeLimit: 1Gi
    nodeSelector:
      kubernetes.io/os: linux
      node-type: worker
    tolerations:
    - key: "ml-workload"
      operator: "Equal"
      value: "true"
      effect: "NoSchedule"
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values: ["xgboost-predictor"]
            topologyKey: kubernetes.io/hostname
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: xgboost-predictor-netpol
  namespace: ml-scheduler
spec:
  podSelector:
    matchLabels:
      app: xgboost-predictor
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: kube-system
    - namespaceSelector:
        matchLabels:
          name: ml-scheduler
    - podSelector:
        matchLabels:
          app: scheduler-plugin
    ports:
    - protocol: TCP
      port: 8080
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: redis-cache
    ports:
    - protocol: TCP
      port: 6379
  - to:
    - podSelector:
        matchLabels:
          app: mlflow-server
    ports:
    - protocol: TCP
      port: 5000
  - to: []
    ports:
    - protocol: TCP
      port: 53
    - protocol: UDP
      port: 53
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: kserve-service-account
  namespace: ml-scheduler
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: kserve-predictor-role
rules:
- apiGroups: [""]
  resources: ["pods", "services", "endpoints", "persistentvolumeclaims", "events", "configmaps", "secrets"]
  verbs: ["get", "list", "watch", "create", "update", "patch"]
- apiGroups: ["apps"]
  resources: ["deployments", "daemonsets", "replicasets", "statefulsets"]
  verbs: ["get", "list", "watch"]
- apiGroups: ["monitoring.coreos.com"]
  resources: ["servicemonitors"]
  verbs: ["get", "create"]
- apiGroups: ["serving.kserve.io"]
  resources: ["inferenceservices"]
  verbs: ["get", "list", "watch", "create", "update", "patch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: kserve-predictor-binding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: kserve-predictor-role
subjects:
- kind: ServiceAccount
  name: kserve-service-account
  namespace: ml-scheduler