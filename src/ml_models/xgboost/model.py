#!/usr/bin/env python3
"""
XGBoost Load Predictor for HYDATIS ML Scheduler.
Predicts future CPU and Memory utilization with target accuracy: 89% CPU, 86% Memory.
"""

import pandas as pd
import numpy as np
import xgboost as xgb
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional, Any
import logging
import joblib
from pathlib import Path
from sklearn.model_selection import train_test_split, TimeSeriesSplit
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.preprocessing import StandardScaler
import mlflow
import mlflow.xgboost

logger = logging.getLogger(__name__)


class HYDATISXGBoostPredictor:
    """XGBoost model for predicting CPU and Memory load on HYDATIS cluster."""
    
    def __init__(self, target_cpu_accuracy: float = 0.89, target_memory_accuracy: float = 0.86):
        self.target_cpu_accuracy = target_cpu_accuracy
        self.target_memory_accuracy = target_memory_accuracy
        
        # XGBoost hyperparameters optimized for time series prediction
        self.cpu_model_params = {
            'objective': 'reg:squarederror',
            'max_depth': 8,
            'learning_rate': 0.1,
            'n_estimators': 200,
            'subsample': 0.8,
            'colsample_bytree': 0.8,
            'random_state': 42,
            'eval_metric': 'rmse'
        }
        
        self.memory_model_params = {
            'objective': 'reg:squarederror',
            'max_depth': 6,
            'learning_rate': 0.08,
            'n_estimators': 250,
            'subsample': 0.85,
            'colsample_bytree': 0.7,
            'random_state': 42,
            'eval_metric': 'rmse'
        }
        
        self.cpu_model = None
        self.memory_model = None
        self.feature_scaler = StandardScaler()
        self.feature_names = []
        
    def prepare_training_data(self, dataset_path: str) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """Prepare training data from engineered features."""
        
        logger.info(f"Loading training data from {dataset_path}")
        
        # Load dataset
        if dataset_path.endswith('.parquet'):
            df = pd.read_parquet(dataset_path)
        else:
            df = pd.read_csv(dataset_path)
        
        # Separate features and targets
        feature_cols = [col for col in df.columns 
                       if col not in ['timestamp', 'instance', 'target_cpu_5m', 'target_cpu_15m', 
                                    'target_memory_5m', 'target_memory_15m']]
        
        X = df[feature_cols].select_dtypes(include=[np.number])
        
        # Targets for CPU and Memory prediction
        targets = {}\n",
        "        if 'target_cpu_5m' in df.columns:\n",
        "            targets['cpu_5m'] = df['target_cpu_5m']\n",
        "        if 'target_cpu_15m' in df.columns:\n",
        "            targets['cpu_15m'] = df['target_cpu_15m']\n",
        "        if 'target_memory_5m' in df.columns:\n",
        "            targets['memory_5m'] = df['target_memory_5m']\n",
        "        if 'target_memory_15m' in df.columns:\n",
        "            targets['memory_15m'] = df['target_memory_15m']\n",
        "\n",
        "        y_df = pd.DataFrame(targets)\n",
        "        \n",
        "        # Clean data\n",
        "        valid_idx = X.notna().all(axis=1) & y_df.notna().all(axis=1)\n",
        "        X_clean = X[valid_idx].fillna(X.median())\n",
        "        y_clean = y_df[valid_idx]\n",
        "        \n",
        "        self.feature_names = list(X_clean.columns)\n",
        "        \n",
        "        logger.info(f\"Training data prepared: {len(X_clean)} samples, {len(self.feature_names)} features\")\n",
        "        \n",
        "        return X_clean, y_clean\n",
        "    \n",
        "    def train_cpu_predictor(self, X: pd.DataFrame, y_cpu: pd.Series, \n",
        "                          validation_split: float = 0.2) -> Dict[str, float]:\n",
        "        \"\"\"Train XGBoost model for CPU load prediction.\"\"\"\n",
        "        \n",
        "        logger.info(\"Training XGBoost CPU load predictor...\")\n",
        "        \n",
        "        # Time-based split for time series data\n",
        "        split_idx = int(len(X) * (1 - validation_split))\n",
        "        X_train, X_val = X.iloc[:split_idx], X.iloc[split_idx:]\n",
        "        y_train, y_val = y_cpu.iloc[:split_idx], y_cpu.iloc[split_idx:]\n",
        "        \n",
        "        # Scale features\n",
        "        X_train_scaled = self.feature_scaler.fit_transform(X_train)\n",
        "        X_val_scaled = self.feature_scaler.transform(X_val)\n",
        "        \n",
        "        # Create XGBoost datasets\n",
        "        dtrain = xgb.DMatrix(X_train_scaled, label=y_train, feature_names=self.feature_names)\n",
        "        dval = xgb.DMatrix(X_val_scaled, label=y_val, feature_names=self.feature_names)\n",
        "        \n",
        "        # Train with early stopping\n",
        "        evals = [(dtrain, 'train'), (dval, 'eval')]\n",
        "        \n",
        "        self.cpu_model = xgb.train(\n",
        "            params=self.cpu_model_params,\n",
        "            dtrain=dtrain,\n",
        "            num_boost_round=500,\n",
        "            evals=evals,\n",
        "            early_stopping_rounds=20,\n",
        "            verbose_eval=False\n",
        "        )\n",
        "        \n",
        "        # Evaluate performance\n",
        "        y_pred = self.cpu_model.predict(dval)\n",
        "        \n",
        "        metrics = {\n",
        "            'rmse': np.sqrt(mean_squared_error(y_val, y_pred)),\n",
        "            'mae': mean_absolute_error(y_val, y_pred),\n",
        "            'r2': r2_score(y_val, y_pred),\n",
        "            'accuracy': 1 - np.mean(np.abs(y_val - y_pred) / (y_val + 1e-8)),\n",
        "            'target_met': (1 - np.mean(np.abs(y_val - y_pred) / (y_val + 1e-8))) >= self.target_cpu_accuracy\n",
        "        }\n",
        "        \n",
        "        logger.info(f\"CPU Predictor Performance: {metrics['accuracy']:.3f} (Target: {self.target_cpu_accuracy:.3f})\")\n",
        "        \n",
        "        return metrics\n",
        "    \n",
        "    def train_memory_predictor(self, X: pd.DataFrame, y_memory: pd.Series,\n",
        "                             validation_split: float = 0.2) -> Dict[str, float]:\n",
        "        \"\"\"Train XGBoost model for Memory load prediction.\"\"\"\n",
        "        \n",
        "        logger.info(\"Training XGBoost Memory load predictor...\")\n",
        "        \n",
        "        # Time-based split\n",
        "        split_idx = int(len(X) * (1 - validation_split))\n",
        "        X_train, X_val = X.iloc[:split_idx], X.iloc[split_idx:]\n",
        "        y_train, y_val = y_memory.iloc[:split_idx], y_memory.iloc[split_idx:]\n",
        "        \n",
        "        # Use same scaler as CPU model\n",
        "        X_train_scaled = self.feature_scaler.transform(X_train)\n",
        "        X_val_scaled = self.feature_scaler.transform(X_val)\n",
        "        \n",
        "        # XGBoost datasets\n",
        "        dtrain = xgb.DMatrix(X_train_scaled, label=y_train, feature_names=self.feature_names)\n",
        "        dval = xgb.DMatrix(X_val_scaled, label=y_val, feature_names=self.feature_names)\n",
        "        \n",
        "        # Train memory model\n",
        "        evals = [(dtrain, 'train'), (dval, 'eval')]\n",
        "        \n",
        "        self.memory_model = xgb.train(\n",
        "            params=self.memory_model_params,\n",
        "            dtrain=dtrain,\n",
        "            num_boost_round=500,\n",
        "            evals=evals,\n",
        "            early_stopping_rounds=20,\n",
        "            verbose_eval=False\n",
        "        )\n",
        "        \n",
        "        # Evaluate performance\n",
        "        y_pred = self.memory_model.predict(dval)\n",
        "        \n",
        "        metrics = {\n",
        "            'rmse': np.sqrt(mean_squared_error(y_val, y_pred)),\n",
        "            'mae': mean_absolute_error(y_val, y_pred),\n",
        "            'r2': r2_score(y_val, y_pred),\n",
        "            'accuracy': 1 - np.mean(np.abs(y_val - y_pred) / (y_val + 1e-8)),\n",
        "            'target_met': (1 - np.mean(np.abs(y_val - y_pred) / (y_val + 1e-8))) >= self.target_memory_accuracy\n",
        "        }\n",
        "        \n",
        "        logger.info(f\"Memory Predictor Performance: {metrics['accuracy']:.3f} (Target: {self.target_memory_accuracy:.3f})\")\n",
        "        \n",
        "        return metrics\n",
        "    \n",
        "    def predict_load(self, features: pd.DataFrame, horizon_minutes: int = 5) -> Dict[str, np.ndarray]:\n",
        "        \"\"\"Predict future CPU and Memory load for scheduling decisions.\"\"\"\n",
        "        \n",
        "        if self.cpu_model is None or self.memory_model is None:\n",
        "            raise ValueError(\"Models not trained yet\")\n",
        "        \n",
        "        # Prepare features\n",
        "        X = features[self.feature_names].fillna(features.median())\n",
        "        X_scaled = self.feature_scaler.transform(X)\n",
        "        \n",
        "        # Create XGBoost matrix\n",
        "        dtest = xgb.DMatrix(X_scaled, feature_names=self.feature_names)\n",
        "        \n",
        "        # Predictions\n",
        "        cpu_pred = self.cpu_model.predict(dtest)\n",
        "        memory_pred = self.memory_model.predict(dtest) if self.memory_model else np.zeros_like(cpu_pred)\n",
        "        \n",
        "        return {\n",
        "            'cpu_prediction': cpu_pred,\n",
        "            'memory_prediction': memory_pred,\n",
        "            'prediction_horizon_minutes': horizon_minutes,\n",
        "            'timestamp': datetime.now()\n",
        "        }\n",
        "    \n",
        "    def get_feature_importance(self) -> Dict[str, Dict[str, float]]:\n",
        "        \"\"\"Get feature importance from trained models.\"\"\"\n",
        "        \n",
        "        importance = {}\n",
        "        \n",
        "        if self.cpu_model:\n",
        "            cpu_importance = self.cpu_model.get_score(importance_type='weight')\n",
        "            importance['cpu_model'] = cpu_importance\n",
        "        \n",
        "        if self.memory_model:\n",
        "            memory_importance = self.memory_model.get_score(importance_type='weight')\n",
        "            importance['memory_model'] = memory_importance\n",
        "        \n",
        "        return importance\n",
        "    \n",
        "    def save_models(self, output_dir: str) -> Dict[str, str]:\n",
        "        \"\"\"Save trained models and metadata.\"\"\"\n",
        "        \n",
        "        output_path = Path(output_dir)\n",
        "        output_path.mkdir(parents=True, exist_ok=True)\n",
        "        \n",
        "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "        saved_files = {}\n",
        "        \n",
        "        # Save models\n",
        "        if self.cpu_model:\n",
        "            cpu_path = output_path / f\"xgboost_cpu_predictor_{timestamp}.json\"\n",
        "            self.cpu_model.save_model(str(cpu_path))\n",
        "            saved_files['cpu_model'] = str(cpu_path)\n",
        "        \n",
        "        if self.memory_model:\n",
        "            memory_path = output_path / f\"xgboost_memory_predictor_{timestamp}.json\"\n",
        "            self.memory_model.save_model(str(memory_path))\n",
        "            saved_files['memory_model'] = str(memory_path)\n",
        "        \n",
        "        # Save scaler\n",
        "        scaler_path = output_path / f\"feature_scaler_{timestamp}.pkl\"\n",
        "        joblib.dump(self.feature_scaler, scaler_path)\n",
        "        saved_files['scaler'] = str(scaler_path)\n",
        "        \n",
        "        # Save metadata\n",
        "        metadata = {\n",
        "            'model_type': 'XGBoost Load Predictor',\n",
        "            'cluster': 'HYDATIS-6node',\n",
        "            'creation_timestamp': datetime.now().isoformat(),\n",
        "            'target_accuracies': {\n",
        "                'cpu': self.target_cpu_accuracy,\n",
        "                'memory': self.target_memory_accuracy\n",
        "            },\n",
        "            'feature_count': len(self.feature_names),\n",
        "            'feature_names': self.feature_names,\n",
        "            'model_params': {\n",
        "                'cpu': self.cpu_model_params,\n",
        "                'memory': self.memory_model_params\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        metadata_path = output_path / f\"model_metadata_{timestamp}.json\"\n",
        "        with open(metadata_path, 'w') as f:\n",
        "            import json\n",
        "            json.dump(metadata, f, indent=2)\n",
        "        \n",
        "        saved_files['metadata'] = str(metadata_path)\n",
        "        \n",
        "        logger.info(f\"Models saved to: {output_dir}\")\n",
        "        \n",
        "        return saved_files\n",
        "    \n",
        "    def load_models(self, model_dir: str) -> bool:\n",
        "        \"\"\"Load pre-trained models from storage.\"\"\"\n",
        "        \n",
        "        try:\n",
        "            model_path = Path(model_dir)\n",
        "            \n",
        "            # Find latest model files\n",
        "            cpu_models = list(model_path.glob(\"xgboost_cpu_predictor_*.json\"))\n",
        "            memory_models = list(model_path.glob(\"xgboost_memory_predictor_*.json\"))\n",
        "            scalers = list(model_path.glob(\"feature_scaler_*.pkl\"))\n",
        "            \n",
        "            if cpu_models:\n",
        "                self.cpu_model = xgb.Booster()\n",
        "                self.cpu_model.load_model(str(sorted(cpu_models)[-1]))\n",
        "                logger.info(f\"CPU model loaded: {sorted(cpu_models)[-1]}\")\n",
        "            \n",
        "            if memory_models:\n",
        "                self.memory_model = xgb.Booster()\n",
        "                self.memory_model.load_model(str(sorted(memory_models)[-1]))\n",
        "                logger.info(f\"Memory model loaded: {sorted(memory_models)[-1]}\")\n",
        "            \n",
        "            if scalers:\n",
        "                self.feature_scaler = joblib.load(str(sorted(scalers)[-1]))\n",
        "                logger.info(f\"Feature scaler loaded: {sorted(scalers)[-1]}\")\n",
        "            \n",
        "            return True\n",
        "            \n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to load models: {e}\")\n",
        "            return False\n",
        "\n",
        "\n",
        "class XGBoostTrainingPipeline:\n",
        "    \"\"\"Complete training pipeline for XGBoost load prediction models.\"\"\"\n",
        "    \n",
        "    def __init__(self, mlflow_tracking_uri: str = \"http://10.110.190.32:31380\"):\n",
        "        self.predictor = HYDATISXGBoostPredictor()\n",
        "        self.mlflow_uri = mlflow_tracking_uri\n",
        "        self.experiment_name = \"hydatis-xgboost-load-prediction\"\n",
        "    \n",
        "    def setup_mlflow_tracking(self):\n",
        "        \"\"\"Setup MLflow experiment tracking.\"\"\"\n",
        "        \n",
        "        mlflow.set_tracking_uri(self.mlflow_uri)\n",
        "        \n",
        "        try:\n",
        "            experiment_id = mlflow.create_experiment(self.experiment_name)\n",
        "        except:\n",
        "            experiment = mlflow.get_experiment_by_name(self.experiment_name)\n",
        "            experiment_id = experiment.experiment_id\n",
        "        \n",
        "        mlflow.set_experiment(self.experiment_name)\n",
        "        logger.info(f\"MLflow experiment: {self.experiment_name}\")\n",
        "    \n",
        "    def run_training_experiment(self, dataset_path: str, experiment_name: str = None) -> Dict[str, Any]:\n",
        "        \"\"\"Run complete XGBoost training experiment with MLflow tracking.\"\"\"\n",
        "        \n",
        "        self.setup_mlflow_tracking()\n",
        "        \n",
        "        run_name = experiment_name or f\"xgboost_run_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "        \n",
        "        with mlflow.start_run(run_name=run_name):\n",
        "            # Log parameters\n",
        "            mlflow.log_params(self.predictor.cpu_model_params)\n",
        "            mlflow.log_param(\"dataset_path\", dataset_path)\n",
        "            mlflow.log_param(\"cluster\", \"HYDATIS-6node\")\n",
        "            \n",
        "            # Prepare data\n",
        "            X, y_df = self.predictor.prepare_training_data(dataset_path)\n",
        "            \n",
        "            # Train CPU model\n",
        "            if 'cpu_5m' in y_df.columns:\n",
        "                cpu_metrics = self.predictor.train_cpu_predictor(X, y_df['cpu_5m'])\n",
        "                \n",
        "                # Log CPU metrics\n",
        "                for metric, value in cpu_metrics.items():\n",
        "                    mlflow.log_metric(f\"cpu_{metric}\", value)\n",
        "            \n",
        "            # Train Memory model\n",
        "            if 'memory_5m' in y_df.columns:\n",
        "                memory_metrics = self.predictor.train_memory_predictor(X, y_df['memory_5m'])\n",
        "                \n",
        "                # Log Memory metrics\n",
        "                for metric, value in memory_metrics.items():\n",
        "                    mlflow.log_metric(f\"memory_{metric}\", value)\n",
        "            \n",
        "            # Log feature importance\n",
        "            importance = self.predictor.get_feature_importance()\n",
        "            if importance:\n",
        "                mlflow.log_dict(importance, \"feature_importance.json\")\n",
        "            \n",
        "            # Save models\n",
        "            model_dir = \"/data/ml_scheduler_longhorn/models/xgboost\"\n",
        "            saved_files = self.predictor.save_models(model_dir)\n",
        "            \n",
        "            # Log model artifacts\n",
        "            for artifact_type, path in saved_files.items():\n",
        "                mlflow.log_artifact(path, f\"models/{artifact_type}\")\n",
        "            \n",
        "            # Overall experiment results\n",
        "            results = {\n",
        "                'cpu_metrics': cpu_metrics if 'cpu_metrics' in locals() else {},\n",
        "                'memory_metrics': memory_metrics if 'memory_metrics' in locals() else {},\n",
        "                'model_files': saved_files,\n",
        "                'feature_count': len(self.predictor.feature_names),\n",
        "                'training_samples': len(X)\n",
        "            }\n",
        "            \n",
        "            # Log overall success\n",
        "            cpu_target_met = cpu_metrics.get('target_met', False) if 'cpu_metrics' in locals() else False\n",
        "            memory_target_met = memory_metrics.get('target_met', False) if 'memory_metrics' in locals() else False\n",
        "            \n",
        "            mlflow.log_metric(\"cpu_target_achieved\", int(cpu_target_met))\n",
        "            mlflow.log_metric(\"memory_target_achieved\", int(memory_target_met))\n",
        "            mlflow.log_metric(\"overall_success\", int(cpu_target_met and memory_target_met))\n",
        "            \n",
        "            logger.info(f\"Training experiment completed: {run_name}\")\n",
        "            logger.info(f\"CPU target achieved: {cpu_target_met}\")\n",
        "            logger.info(f\"Memory target achieved: {memory_target_met}\")\n",
        "            \n",
        "            return results\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main XGBoost development function.\"\"\"\n",
        "    \n",
        "    # Initialize training pipeline\n",
        "    pipeline = XGBoostTrainingPipeline()\n",
        "    \n",
        "    print(\"HYDATIS XGBoost Load Predictor - Week 5\")\n",
        "    print(f\"Target Accuracies: 89% CPU, 86% Memory\")\n",
        "    print(f\"MLflow Tracking: {pipeline.mlflow_uri}\")\n",
        "    \n",
        "    return pipeline\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    pipeline = main()